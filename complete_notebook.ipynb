{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download the CheXchoNet dataset\n",
        "\n",
        "| Dataset  | Images | Size |\n",
        "| -------- | ------ | ---- |\n",
        "| [CheXchoNet](https://physionet.org/content/chexchonet/1.0.0/)  | 71,589 | 2.7 GB |"
      ],
      "metadata": {
        "id": "4MGp-hlniQNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter physionet username\n",
        "PHYSIONET_USERNAME=input('Physionet Username:')"
      ],
      "metadata": {
        "id": "_QRoqEfNiZes"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the files\n",
        "!wget -r -N -c -np --user {PHYSIONET_USERNAME} --ask-password https://physionet.org/files/chexchonet/1.0.0/"
      ],
      "metadata": {
        "id": "qHUnJStNiUq3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now move the images to the correct path\n",
        "import os\n",
        "OUTPUT_IMAGE_PATH = './cxrs/'\n",
        "os.rename('physionet.org/files/chexchonet/1.0.0/images/', './cxrs')\n",
        "\n",
        "# Now move the csv to a local folder\n",
        "import pandas as pd\n",
        "OUTPUT_METADATA_PATH = './diffusion_out/'\n",
        "if not os.path.exists(OUTPUT_METADATA_PATH):\n",
        "  os.makedirs(OUTPUT_METADATA_PATH)\n",
        "metadata_df = pd.read_csv('physionet.org/files/chexchonet/1.0.0/metadata.csv')\n",
        "metadata_df.to_csv(os.path.join(OUTPUT_METADATA_PATH, 'metadata.csv'), index=False)"
      ],
      "metadata": {
        "id": "mIGWS7Ddjt7l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separate into Training, Validation, and Testing Splits"
      ],
      "metadata": {
        "id": "Lv8Y6HwEjdWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "OUTPUT_METADATA_PATH = './diffusion_out/'\n",
        "RANDOM_SEED = None\n",
        "\n",
        "# Create the output directory\n",
        "import os\n",
        "if not os.path.exists(OUTPUT_METADATA_PATH):\n",
        "  os.makedirs(OUTPUT_METADATA_PATH)\n",
        "\n",
        "# Seed if defined\n",
        "import random\n",
        "if RANDOM_SEED is not None:\n",
        "  random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "C3PzH7RTkdTC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now load the data\n",
        "chexchonet_df = pd.read_csv(os.path.join(OUTPUT_METADATA_PATH, 'metadata.csv'))\n",
        "chexchonet_df['file_path'] = chexchonet_df['cxr_path']"
      ],
      "metadata": {
        "id": "j9ZAU7pnNL32"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_list(data, train_split=0.9, test_split=0.05, valid_split=0.05):\n",
        "    if train_split + test_split + valid_split > 1.0:\n",
        "        raise ValueError('The splits must sum up to 1.0')\n",
        "\n",
        "    # Shuffle the list randomly\n",
        "    random.shuffle(data)\n",
        "\n",
        "    # Calculate the split indices\n",
        "    train_end = int(train_split * len(data))\n",
        "    test_end = train_end + int(test_split * len(data))\n",
        "\n",
        "    # Split the data\n",
        "    train_data = data[:train_end]\n",
        "    test_data = data[train_end:test_end]\n",
        "    valid_data = data[test_end:]\n",
        "\n",
        "    return set(train_data), set(test_data), set(valid_data)\n",
        "\n",
        "# Spliy into the datasets\n",
        "train, test, valid = split_list(chexchonet_df.patient_id.unique())\n",
        "def map_set(v):\n",
        "  if v in train:\n",
        "    return 'train'\n",
        "  elif v in test:\n",
        "    return 'test'\n",
        "  else:\n",
        "    return 'valid'\n",
        "\n",
        "# Now map and label\n",
        "chexchonet_df['sex_m'] = chexchonet_df['sex'].map(lambda x: 1 if x == 'M' else 0)\n",
        "chexchonet_df['sex_f'] = chexchonet_df['sex'].map(lambda x: 1 if x == 'F' else 0)\n",
        "\n",
        "chexchonet_df['diffusion_set'] = chexchonet_df['patient_id'].apply(map_set)\n",
        "chexchonet_df['inference_set'] = chexchonet_df['patient_id'].apply(map_set)"
      ],
      "metadata": {
        "id": "z2psQ-8VjnGt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now output\n",
        "chexchonet_df[chexchonet_df['diffusion_set'] == 'train'].to_csv(os.path.join(OUTPUT_METADATA_PATH, 'diffusion_metadata_train.csv'), index=False)\n",
        "chexchonet_df[chexchonet_df['diffusion_set'] == 'valid'].to_csv(os.path.join(OUTPUT_METADATA_PATH, 'diffusion_metadata_eval.csv'), index=False)\n",
        "chexchonet_df[chexchonet_df['diffusion_set'] == 'test'].to_csv(os.path.join(OUTPUT_METADATA_PATH, 'diffusion_metadata_test.csv'), index=False)"
      ],
      "metadata": {
        "id": "PXi9u_PVk8bx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the DDPM Model"
      ],
      "metadata": {
        "id": "h6UK_vIUk7RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the files\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip install diffusers==0.28.0 > /dev/null 2>&1\n",
        "!pip install accelerate > /dev/null 2>&1\n",
        "!rm -rf cxr_ddpm\n",
        "!git clone https://github.com/cstreiffer/cxr_ddpm.git\n",
        "\n",
        "# File path maniupation\n",
        "import sys\n",
        "sys.path.append('cxr_ddpm/src/train/')"
      ],
      "metadata": {
        "id": "7JQWZfXAJaRU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the config file\n",
        "from run import load_file\n",
        "OUTPUT_METADATA_PATH = 'diffusion_out/'\n",
        "OUTPUT_MODEL_PATH = 'diffusion_out/model/'\n",
        "CONFIG_FILE_PATH = 'cxr_ddpm/src/train/training_configs/class_diffusion_large_224.yaml'\n",
        "args = load_file(CONFIG_FILE_PATH)\n",
        "\n",
        "# Now specify paths\n",
        "args.metadata_df_paths['train_metadata_path'] = os.path.join(OUTPUT_METADATA_PATH, 'diffusion_metadata_train.csv')\n",
        "args.metadata_df_paths['eval_metadata_path'] = os.path.join(OUTPUT_METADATA_PATH, 'diffusion_metadata_eval.csv')\n",
        "args.metadata_df_paths['test_metadata_path'] = os.path.join(OUTPUT_METADATA_PATH, 'diffusion_metadata_test.csv')\n",
        "args.model_output_path = OUTPUT_METADATA_PATH"
      ],
      "metadata": {
        "id": "oizn70_inaSg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from run import run\n",
        "run(args)"
      ],
      "metadata": {
        "id": "uCdhiswbngSm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Synthetic Data"
      ],
      "metadata": {
        "id": "SzOjB2u2l4tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gen_images import gen\n",
        "import numpy as np\n",
        "\n",
        "# Define paths\n",
        "MODEL_INPUT_PATH = \"diffusion_out/class_diffusion_large_224x224/\"\n",
        "OUTPUT_GEN_PATH = \"diffusion_out/gen_images\"\n",
        "NUM_BATCHES = 10 # Total number of batches to run\n",
        "BATCH_SIZE = 16 # Modify this based on available GPU RAM\n",
        "\n",
        "# Define custom sample function\n",
        "def sample_context(bs):\n",
        "  #   - age   (norm)\n",
        "  #   - sex_m (one-hot)\n",
        "  #   - sex_f (one-hot)\n",
        "  #   - ivsd  (norm)\n",
        "  #   - lvpwd (norm)\n",
        "  #   - lvidd (norm)\n",
        "  s = [np.random.choice([0,1]) for i in range(bs)]\n",
        "  return [[\n",
        "      np.random.normal(loc=-.5, scale=1.0),\n",
        "      s[i],\n",
        "      1 if s[i] == 0 else 0,\n",
        "      np.random.normal(loc=.5, scale=1.0),\n",
        "      np.random.normal(loc=.5, scale=1.0),\n",
        "      np.random.normal(loc=.5, scale=1.0)\n",
        "  ] for i in range(bs)]\n",
        "\n",
        "df = gen(\n",
        "    MODEL_INPUT_PATH,\n",
        "    OUTPUT_GEN_PATH,\n",
        "    NUM_BATCHES,\n",
        "    BATCH_SIZE,\n",
        "    sample_fn=sample_context\n",
        ")"
      ],
      "metadata": {
        "id": "iDVw-HUMnjmn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Synthetic Data"
      ],
      "metadata": {
        "id": "QzKEP2Zil6gV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inception Score"
      ],
      "metadata": {
        "id": "xMfNsKw0IxzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from eval import inception_score\n",
        "\n",
        "train_file_path = os.path.join(OUTPUT_METADATA_PATH, 'diffusion_metadata_train.csv')\n",
        "test_file_path  = os.path.join(OUTPUT_METADATA_PATH, 'diffusion_metadata_test.csv')\n",
        "gen_file_path   = os.path.join(OUTPUT_GEN_PATH, 'gen_metadata.csv')\n",
        "\n",
        "train_is = inception_score(train_file_path)\n",
        "test_is = inception_score(test_file_path)\n",
        "gen_is = inception_score(gen_file_path)\n",
        "\n",
        "print(f\"Train Score: {train_is:0.4f}\")\n",
        "print(f\"Test Score: {test_is:0.4f}\")\n",
        "print(f\"Gen Score: {gen_is:0.4f}\")"
      ],
      "metadata": {
        "id": "BLsnlNVTIzeH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FID Score"
      ],
      "metadata": {
        "id": "V0lZSEjm__rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-fid"
      ],
      "metadata": {
        "id": "93g1CIkN_891"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pytorch_fid {os.path.join(OUTPUT_GEN_PATH, \"images\")} cxrs/ --device cuda:0"
      ],
      "metadata": {
        "id": "kh6FZ_6eACoE"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}